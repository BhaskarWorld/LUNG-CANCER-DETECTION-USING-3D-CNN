{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import xlrd \n",
    "import h5py\n",
    "import keras\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "import pydicom as dicom\n",
    "import matplotlib.pyplot as plot\n",
    "from ipywidgets import IntProgress\n",
    "from keras.models import Sequential\n",
    "from tqdm.notebook import tqdm as tq\n",
    "from keras.utils import to_categorical\n",
    "from skimage import measure,morphology,segmentation\n",
    "from keras.layers import Dense, Flatten, Conv3D, MaxPooling3D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load a patient CT Scan\n",
    "input_patient_path = 'D:/Study Materials/My Projects/cancer/LUNG CT SCAN DATASET/SPIE-AAPM Lung CT Challenge/Train/CT-Training-BE001'\n",
    "def load_patient_CT_scan(input_patient_path):\n",
    "    \n",
    "    # loading dicom file of a patient\n",
    "    dicom_lung_slices = [dicom.read_file(os.path.join(input_patient_path,dicom_lung_slice)) for dicom_lung_slice in os.listdir(input_patient_path)]\n",
    "    # sorting dicom slices w.r.t the 'Instance Number'\n",
    "    dicom_lung_slices.sort(key=lambda x : int(x.InstanceNumber))\n",
    "    # extracting image array from the dicom slices\n",
    "    lung_image_slices = np.stack([dicom_lung_slice.pixel_array for dicom_lung_slice in dicom_lung_slices])\n",
    "    \n",
    "    return dicom_lung_slices , lung_image_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Convert the lung image to Hounsfield Units (HU)\n",
    "def convert_img_hu(dicom_lung_slices , lung_image_slices):\n",
    "    \n",
    "    # Converting the image array to int16 \n",
    "    lung_image_slices = lung_image_slices.astype(np.int16)\n",
    "    \n",
    "    # Set outside-of-scan pixels to 0\n",
    "    # The intercept is usually -1024, so air is approximately 0\n",
    "    lung_image_slices[lung_image_slices == -2000] = 0\n",
    "    \n",
    "    # Converting the image array to Hounsfield Units (HU)\n",
    "    for slice_count in range(len(dicom_lung_slices)):\n",
    "        \n",
    "        # Obtaining Rescle Slope and Intercept from the dicom slices\n",
    "        slope = dicom_lung_slices[slice_count].RescaleSlope\n",
    "        intercept = dicom_lung_slices[slice_count].RescaleIntercept\n",
    "        \n",
    "        # Applying Slope and Intercept value to convert into HU\n",
    "        if slope != 1:\n",
    "            lung_image_slices[slice_count] = slope * lung_image_slices[slice_count].astype(np.float64)\n",
    "            lung_image_slices[slice_count] = lung_image_slices[slice_count].astype(np.int16)\n",
    "            \n",
    "        lung_image_slices[slice_count] += np.int16(intercept)\n",
    "    \n",
    "    return np.array(lung_image_slices, dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Convert the lung image from Hounsfield Units (HU) to original\n",
    "def convert_img_hu_to_original(dicom_lung_slices , lung_image_slices_hu_reshaped):\n",
    "    \n",
    "    # Converting the image array to int16 \n",
    "    lung_image_slices_hu_reshaped = lung_image_slices_hu_reshaped.astype(np.int16)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Converting the image array to Hounsfield Units (HU)\n",
    "    for slice_count in range(len(dicom_lung_slices)):\n",
    "        \n",
    "        # Obtaining Rescle Slope and Intercept from the dicom slices\n",
    "        slope = dicom_lung_slices[slice_count].RescaleSlope\n",
    "        intercept = dicom_lung_slices[slice_count].RescaleIntercept\n",
    "        \n",
    "        # Applying Slope and Intercept value to convert into HU\n",
    "        if slope != 1:\n",
    "            lung_image_slices_hu_reshaped[slice_count] = slope / lung_image_slices_hu_reshaped[slice_count].astype(np.float64)\n",
    "            lung_image_slices_hu_reshaped[slice_count] = lung_image_slices_hu_reshaped[slice_count].astype(np.int16)\n",
    "            \n",
    "        lung_image_slices_hu_reshaped[slice_count] -= np.int16(intercept)\n",
    "    \n",
    "    return np.array(lung_image_slices_hu_reshaped, dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to resample the image array into uniform spacing (1,1,1)\n",
    "def resample_lung_img(dicom_lung_slices , lung_image_slices_hu, new_spacing = [1,1,1]):\n",
    "    \n",
    "    # Obtaining the current spacing of the image array from the dicom slices\n",
    "    slice_thickness = [dicom_lung_slices[0].SliceThickness] #slice thickness\n",
    "    slice_pixel_spacing = dicom_lung_slices[0].PixelSpacing #Slice pixel spacing\n",
    "    \n",
    "    # Merging  SliceThickness and PixelSpacing into a list\n",
    "    slice_thickness.extend(slice_pixel_spacing) \n",
    "    \n",
    "    # Converting spacing to float32\n",
    "    current_spacing= np.array(slice_thickness, dtype=(np.float32))\n",
    "    \n",
    "    \n",
    "    # Calculating reshape factor\n",
    "    reshape_factor = current_spacing / new_spacing\n",
    "    new_img_shape = reshape_factor * lung_image_slices_hu.shape\n",
    "    rounded_img_shape = np.round(new_img_shape)\n",
    "    \n",
    "    # shape cannot be in float so rounding the shape and \n",
    "    # obtaing the updated reshape factor\n",
    "    actual_reshape_factor = rounded_img_shape / lung_image_slices_hu.shape\n",
    "    new_spacing = current_spacing / actual_reshape_factor\n",
    "    \n",
    "    # Interpolating image array to resample to spacing (1, 1, 1)\n",
    "    lung_image_slices_hu = scipy.ndimage.interpolation.zoom(lung_image_slices_hu, actual_reshape_factor, mode='nearest')\n",
    "    \n",
    "    \n",
    "    return  lung_image_slices_hu, new_spacing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def largest_label_volume(im, bg=-1):\n",
    "    # get the unique values and their no of occurence(count) in the image\n",
    "    vals, counts = np.unique(im, return_counts=True)\n",
    "\n",
    "    # removing the counts which have 'value' equal to 'bg'\n",
    "    counts = counts[vals != bg]\n",
    "    # removing the values which have 'value' equal to 'bg'\n",
    "    vals = vals[vals != bg]\n",
    "\n",
    "    # obtaining the indexes which have max count/ occurence in the image\n",
    "    if len(counts) > 0:\n",
    "        \n",
    "        # keeping the 'values' which have max occurences with the help of 'counts'\n",
    "        return vals[np.argmax(counts)]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "# this function gets the lungs segmented by forming a lung mask and\n",
    "# multiply the mask with the image\n",
    "def segment_lung_mask(image, fill_lung_structures=True):\n",
    "    \n",
    "    \n",
    "    # not actually binary, but 1 and 2. \n",
    "    # 0 is treated as background, which we do not want as 'measure.label' has background = 0 as default\n",
    "    binary_image = np.array(image > -420, dtype=np.int8)+1\n",
    "    \n",
    "    # labels the binary mask \n",
    "    labels = measure.label(binary_image)\n",
    "    \n",
    "    # Pick the pixel in the very corner to determine which label is air.\n",
    "    #   Improvement: Pick multiple background labels from around the patient\n",
    "    #   More resistant to \"trays\" on which the patient lays cutting the air \n",
    "    #   around the person in half\n",
    "    # since the trays blocks the connectivity of the air above it \n",
    "    # therefore label values for upward air is not equal to the labeled values of air below the tray  \n",
    "    background_label = labels[0,0,0]\n",
    "    \n",
    "    # Fill the air 'above the tray' around the person\n",
    "    binary_image[background_label == labels] = 2\n",
    "    \n",
    "    \n",
    "    # Method of filling the lung structures (that is superior to something like \n",
    "    # morphological closing)\n",
    "    if fill_lung_structures:\n",
    "        # For every slice we determine the largest solid structure\n",
    "        # 'for loop' is used because if we label the whole 3D image then \n",
    "        # the largest area would be the lungs\n",
    "        for i, axial_slice in enumerate(binary_image):\n",
    "            # converting it to 0,1 as 0 values are treated \n",
    "            # as background for 'measure.label' function\n",
    "            axial_slice = axial_slice - 1 \n",
    "            # labelling the areas except the lungs\n",
    "            labeling = measure.label(axial_slice)\n",
    "            # getting the label which has the highest no. of counts\n",
    "            l_max = largest_label_volume(labeling, bg=0)\n",
    "            \n",
    "            # applying 1 to the labeled values which no. of counts is not the highest\n",
    "            # This will make the nodules value the same as the lung value i.e 1\n",
    "            if l_max is not None: #This slice contains some lung\n",
    "                binary_image[i][labeling != l_max] = 1\n",
    "\n",
    "    \n",
    "    binary_image -= 1 #Make the image actual binary\n",
    "    binary_image = 1-binary_image # Invert it, lungs are now 1\n",
    "    \n",
    "    # Remove other air pockets insided body\n",
    "    # the motive is to label all the areas including air pockets\n",
    "    # and then obtain the lung area using 'largest_label_volume' function\n",
    "    # and then remove other areas  from the binary image which are not lung areas \n",
    "    # those are air pockets\n",
    "    labels = measure.label(binary_image, background=0)\n",
    "    plot.imshow(binary_image[80],cmap=plot.cm.bone)\n",
    "    l_max = largest_label_volume(labels, bg=0)\n",
    "    if l_max is not None: # There are air pockets\n",
    "        binary_image[labels != l_max] = 0\n",
    "    \n",
    "        \n",
    "    return binary_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to resize the image\n",
    "\n",
    "def resize_voxel(Image3D,size=(100,100)):\n",
    "    resized_image = []\n",
    "    for i in range(len(Image3D)):\n",
    "        resized_image.append(cv2.resize(Image3D[i],size))\n",
    "        \n",
    "    return np.asarray(resized_image,dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Patients_Path = \"D:/Study Materials/My Projects/cancer/LUNG CT SCAN DATASET/SPIE-AAPM Lung CT Challenge/Train/\"\n",
    "Train_Patients = os.listdir(Train_Patients_Path)\n",
    "Save_Path = \"D:/Study Materials/My Projects/cancer/LUNG CT SCAN DATASET/SPIE-AAPM Lung CT Challenge/Preprocessed_Train_Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to take 100 slices w.r.t the nodule center image \n",
    "def crop_cube(image,Nodule_Location,cube_size = 100):\n",
    "    image_shape = image.shape\n",
    "    upper_z = Nodule_Location - (cube_size//2)\n",
    "    lower_z = Nodule_Location + (cube_size//2)\n",
    "    if(upper_z < 0):\n",
    "        upper_z = 0\n",
    "        lower_z = upper_z + cube_size\n",
    "    elif(lower_z > image_shape[0]):\n",
    "        lower_z = image_shape[0]\n",
    "        upper_z = lower_z - cube_size\n",
    "           \n",
    "    image = image[upper_z:lower_z]\n",
    "    \n",
    "    return np.array(image,dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d2ea8504a244e6c8985d471d1678474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Progress', max=1.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Nodule Cube Size\n",
    "Nodule_cube_size = 100\n",
    "\n",
    "# Calculating the maximum no. of slice a patient has.\n",
    "# max_slices = np.max([len(slices) for slices in [os.listdir(Train_Patients_Path + Patients) for Patients in Train_Patients]])\n",
    "\n",
    "# Loading the 'Nodule_locations' from xlsx file provided\n",
    "xlsx_path = (\"D:/Study Materials/My Projects/cancer/LUNG CT SCAN DATASET/CalibrationSet_NoduleData.xlsx\") #Xlsx label path \n",
    "wb = xlrd.open_workbook(xlsx_path) #opening the workbook(xlsx file)\n",
    "sheet = wb.sheet_by_index(0) \n",
    "\n",
    "# Extracting the 'Nodule_locations' \n",
    "Nodule_locations_list = [[sheet.cell_value(i, 0) ,  int(sheet.cell_value(i, 1))] for i in range(1,11)]\n",
    "\n",
    "\n",
    "\n",
    "for patients_nodules in tq(Nodule_locations_list[:1],desc=\"Progress\"):\n",
    "    patients = patients_nodules[0] #PatientName\n",
    "    nodule_location = patients_nodules[1] #Patient'sNoduleCenterImage\n",
    "    # loading patient dicoms\n",
    "    dicom_lung_slices , lung_image_slices = load_patient_CT_scan(Train_Patients_Path + patients)\n",
    "    plot.imshow(lung_image_slices[80],cmap=plot.cm.bone)\n",
    "    plot.savefig('Original_image_2.png',dpi=1200)\n",
    "    # converting image to Hounsfield Units (HU)\n",
    "    lung_image_slices_hu = convert_img_hu(dicom_lung_slices , lung_image_slices)\n",
    "    # segmenting the lung nodules\n",
    "    \n",
    "    segmented_lungs = segment_lung_mask(lung_image_slices_hu, False)\n",
    "    segmented_lungs_fill = segment_lung_mask(lung_image_slices_hu, True)\n",
    "    # converting back to original pixel value\n",
    "    lung_image_slices = convert_img_hu_to_original(dicom_lung_slices , lung_image_slices_hu)\n",
    "    # Applying segmented Nodule mask with actual image\n",
    "    image_3D_Nodules = (segmented_lungs_fill-segmented_lungs) * lung_image_slices\n",
    "    # Taking 100 slices w.r.t nodule center image location \n",
    "    nodule_cube = crop_cube(image_3D_Nodules,nodule_location, Nodule_cube_size)\n",
    "    # Resampling the image array to spacing(1,1,1)\n",
    "    nodule_cube_resampled,new_spacing = resample_lung_img(dicom_lung_slices , nodule_cube, new_spacing = [1,1,1])\n",
    "    # resized the image array to (* ,100,100)\n",
    "    nodule_cube_resampled = resize_voxel(nodule_cube_resampled,size=(100,100))\n",
    "    # checking the image shape\n",
    "    image_shape = list(nodule_cube_resampled.shape)\n",
    "    \n",
    "    # extracting the no of slices \n",
    "    #image_shape[0] = max_slices -image_shape[0]\n",
    "    # preparing additional slices for padding\n",
    "    #slice_extend = np.zeros(image_shape, dtype=np.int16)\n",
    "    # adding the padding to the image to maake all the patient images uniform\n",
    "    #extended_image = np.concatenate((image_3D_Nodules, slice_extend)) \n",
    "   \n",
    "    # Saving the result as npy \n",
    "    #np.save(Save_Path+patients+\".npy\",nodule_cube_resampled)\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----Preparatory code ----\n",
    "# Model configuration\n",
    "batch_size = 2\n",
    "no_epochs = 30\n",
    "learning_rate = 0.001\n",
    "no_classes = 2\n",
    "validation_split = 0.2\n",
    "verbosity = 1\n",
    "sample_shape = (100,100,100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulating the data to feed into the model\n",
    "\n",
    "# Loading the labels from xlsx file provided\n",
    "xlsx_path = (\"D:/Study Materials/My Projects/cancer/LUNG CT SCAN DATASET/CalibrationSet_NoduleData.xlsx\") #Xlsx label path \n",
    "wb = xlrd.open_workbook(xlsx_path) #opening the workbook(xlsx file)\n",
    "sheet = wb.sheet_by_index(0) \n",
    "\n",
    "# Extracting the labels and set malignant to 1 and benign to 0\n",
    "labels = np.array([[sheet.cell_value(i, 0) , 1 if sheet.cell_value(i, 3)=='malignant' else 0 ] for i in range(1,11)])\n",
    "labels = np.sort(labels,axis = 0) #sorted the list row-wise\n",
    "Patient_numpy=[] # Creating empty list\n",
    "\n",
    "# Loading the patients numpy data and adding its label taking the 'patient names' and 'labels' from the Label array\n",
    "Patient_numpy=np.array([[np.load(Save_Path+labels[i][0]+'.npy'),int(labels[i][1])] for i in range(len(labels))])\n",
    "\n",
    "# Splitting data into 80% training and 20% testing\n",
    "Train = np.append(Patient_numpy[:3],Patient_numpy[5:8],axis=0)\n",
    "Test = [Patient_numpy[4],Patient_numpy[9]]\n",
    "Validation = [Patient_numpy[3],Patient_numpy[8]]\n",
    "\n",
    "# Separating Train Data,Train Labels and Test Data, Testy Labels\n",
    "Train_data = [Train[i][0] for i in range(len(Train))]\n",
    "Test_data = [Test[i][0] for i in range(len(Test))]\n",
    "Validation_data = [Validation[i][0] for i in range(len(Validation))]\n",
    "\n",
    "Train_labels = [Train[i][1] for i in range(len(Train))]\n",
    "Test_labels = [Test[i][1] for i in range(len(Test))]\n",
    "Validation_labels = [Validation[i][1] for i in range(len(Validation))]\n",
    "\n",
    "# One_Hot_Encoding the Training and Testing Labels\n",
    "Train_labels = to_categorical(Train_labels).astype(np.integer)\n",
    "Test_labels = to_categorical(Test_labels).astype(np.integer)\n",
    "Validation_labels = to_categorical(Validation_labels).astype(np.integer)\n",
    "\n",
    "# Estimating the shape of the Training Data and Testing Data that can be fed into the CNN \n",
    "Train_data_shape = (np.shape(Train_data)[0],np.shape(Train_data)[1],np.shape(Train_data)[2],np.shape(Train_data)[3],1)\n",
    "Test_data_shape = (np.shape(Test_data)[0],np.shape(Test_data)[1],np.shape(Test_data)[2],np.shape(Test_data)[3],1)\n",
    "Validation_data_shape = (np.shape(Validation_data)[0],np.shape(Validation_data)[1],np.shape(Validation_data)[2],np.shape(Validation_data)[3],1)\n",
    "\n",
    "\n",
    "# Reshaping the Training Data and Testing Data according to to model need\n",
    "Train_data = np.array(Train_data,dtype=np.int16).reshape(Train_data_shape)\n",
    "Test_data = np.array(Test_data,dtype=np.int16).reshape(Test_data_shape)\n",
    "Validation_data = np.array(Validation_data,dtype=np.int16).reshape(Validation_data_shape)\n",
    "print(Train_data.shape,Test_data.shape,Validation_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=sample_shape))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(no_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(lr=learning_rate),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit data to model\n",
    "history = model.fit(Train_data, Train_labels, batch_size=batch_size,\n",
    "            epochs=no_epochs,\n",
    "            verbose=verbosity,\n",
    "            validation_data=(Validation_data, Validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate generalization metrics\n",
    "score = model.evaluate(Test_data, Test_labels, verbose=0)\n",
    "print(f'Test loss: {score[0]} | Test accuracy: {score[1]}')\n",
    "\n",
    "# Plot history: Categorical crossentropy & Accuracy\n",
    "plot.plot(history.history['loss'], label='Categorical crossentropy (training data)')\n",
    "plot.plot(history.history['val_loss'], label='Categorical crossentropy (validation data)')\n",
    "plot.plot(history.history['accuracy'], label='Accuracy (training data)')\n",
    "plot.plot(history.history['val_accuracy'], label='Accuracy (validation data)')\n",
    "plot.title('Model performance for 3D MNIST Keras Conv3D example')\n",
    "plot.ylabel('Loss value')\n",
    "plot.xlabel('No. epoch')\n",
    "plot.legend(loc=\"upper right\")\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
